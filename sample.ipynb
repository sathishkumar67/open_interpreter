{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d7c83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mss in c:\\users\\sathish\\miniconda3\\envs\\py3.10\\lib\\site-packages (from -r requirements.txt (line 1)) (10.1.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\sathish\\miniconda3\\envs\\py3.10\\lib\\site-packages (from -r requirements.txt (line 2)) (1.40.52)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.52 in c:\\users\\sathish\\miniconda3\\envs\\py3.10\\lib\\site-packages (from boto3->-r requirements.txt (line 2)) (1.40.52)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\sathish\\miniconda3\\envs\\py3.10\\lib\\site-packages (from boto3->-r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in c:\\users\\sathish\\miniconda3\\envs\\py3.10\\lib\\site-packages (from boto3->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\sathish\\miniconda3\\envs\\py3.10\\lib\\site-packages (from botocore<1.41.0,>=1.40.52->boto3->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\sathish\\miniconda3\\envs\\py3.10\\lib\\site-packages (from botocore<1.41.0,>=1.40.52->boto3->-r requirements.txt (line 2)) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sathish\\miniconda3\\envs\\py3.10\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.52->boto3->-r requirements.txt (line 2)) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2beca7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpreter import OpenInterpreter\n",
    "from interpreter.capture import take_screenshot\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60e9d3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"YOU ARE AN EXPERT GUI AUTOMATION AGENT THAT PERFORMS TASKS IN USER INTERFACES.\n",
    "TO PERFORMING KEYBOARD ACTIONS YOU WILL USE \"pyautogui\" LIBRARY.\n",
    "RIGHT NOW YOU WILL PERFORM ALL THE NAVIGATION USING KEYBOARD SHORTCUTS.\n",
    "YOU WILL NOT MOVE MOUSE AND PERFORM MOUSE CLICKS.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e2cd7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYSTEM_PROMPT = \"\"\"\n",
    "# You are an expert GUI automation agent that performs tasks in web browsers. \n",
    "# You analyze screenshots and user queries to determine the exact sequence of actions needed.\n",
    "# You can only interact with the GUI using keyboard actions. So use keyboard shortcuts to navigate and perform tasks.\n",
    "# When typing mention where you are typing (e.g., address bar, search box, form field).\n",
    "# Process Flow:\n",
    "#     1. Analyze the current screenshot and query to understand the task\n",
    "#     2. Reason step-by-step about required actions to take based on the current screen state.\n",
    "#     3. After reasoning all the steps, you will describe and execute one action by outputting a JSON object with the required action.\n",
    "#     4. Wait for a new screenshot to be provided. Use this screenshot to check if the action was successful before continuing with the next action. If the action was not successful, adjust your approach based on the new screenshot.\n",
    "#     5. Output plain text when keyboard actions are not required.\n",
    "#     6. Repeat steps 1-5 until the task is complete.\n",
    "#     7. Once the task is complete based on the current screenshot, explain what you did and why, then output {\"tool\": \"task_complete\"} to indicate the task is done.\n",
    "# Output Format:\n",
    "#     1. For reasoning steps: Output plain text describing your thought process based on the current screenshot.\n",
    "#     2. For keyboard actions: Output description of the action being taken based on the current screenshot and the python code to execute the action based on the current screenshot.\n",
    "# program: \n",
    "#     1. Use the pyautogui library to perform keyboard actions. \n",
    "#     2. Import pyautogui at the start of your program.\n",
    "#     3. Use pyautogui.hotkey() for keyboard shortcuts. \n",
    "#     4. When typing go to the appropriate field first (e.g., address bar) then use pyautogui.write() to type.\n",
    "# Important Notes:\n",
    "#     1. Always analyze the current screenshot before taking any action.\n",
    "#     2. If an action does not lead to the expected result of the task, adjust your approach based on the new screenshot.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e26d00bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = OpenInterpreter()\n",
    "\n",
    "interpreter.llm.model = \"azure/gpt-4.1\"\n",
    "interpreter.llm.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "interpreter.llm.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "interpreter.llm.api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "interpreter.auto_run = True\n",
    "interpreter.system_message = SYSTEM_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eac7309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'assistant',\n",
       "  'type': 'image',\n",
       "  'format': 'path',\n",
       "  'content': 'screenshots\\\\screenshot_20251015_185202.png'},\n",
       " {'role': 'assistant',\n",
       "  'type': 'code',\n",
       "  'format': 'python',\n",
       "  'content': \"import pyautogui\\nimport time\\n\\ntime.sleep(1)\\n# Press Ctrl + E to go to the search bar in Teams\\npyautogui.hotkey('ctrl', 'e')\\ntime.sleep(0.5)\\n# Type the name 'Harshit Sharma' and press Enter\\npyautogui.typewrite('Harshit Sharma')\\ntime.sleep(0.5)\\npyautogui.press('enter')\\ntime.sleep(1)\\n# Press Tab to jump to the message box (may need extra tabs depending on Teams layout)\\npyautogui.press('tab')\\npyautogui.press('tab')\\n\"},\n",
       " {'role': 'computer', 'type': 'console', 'format': 'output', 'content': ''},\n",
       " {'role': 'assistant',\n",
       "  'type': 'message',\n",
       "  'content': 'I have navigated to the search bar in MS Teams using keyboard shortcuts, searched for \"Harshit Sharma,\" and moved the focus towards the chat/message box. You can now type your message directly. Let me know what you would like to send to Harshit Sharma!'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query to ask the assistant\n",
    "query = \"open ms teams, msg Harshit Sharma\"\n",
    "# query = \"In this sheet, create 10 students 5 subject and give them the average score and percentage in new column.\"\n",
    "# query = \"In this sheet, create sheet 2. copy all the data from sheet 1 and paste it in sheet 2.\"\n",
    "\n",
    "# Build the message with optional image\n",
    "message_with_image = [{\"role\": \"user\", \"type\": \"message\", \"content\": query},\n",
    "                      {\"role\": \"user\", \"type\": \"image\", \"format\": \"path\", \"content\": take_screenshot()}]\n",
    "\n",
    "interpreter.chat(message_with_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac83b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
